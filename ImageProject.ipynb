{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dfab69b-a5aa-4dc6-97b8-935f8fd1a3ec",
   "metadata": {},
   "source": [
    "\n",
    "# Introduction\n",
    "\n",
    "This script is designed to efficiently organize and compress image files from a source directory. It provides an automated solution to sort images by year, optimize their size, and ensure a clean folder structure. Various functions and modules are utilized to accomplish a range of tasks.\n",
    "\n",
    "## Main Features\n",
    "\n",
    "- **Organize Images by Year**: Sorts images into year-based folders based on EXIF data or filenames.\n",
    "- **Image Compression**: Compresses large images to save storage space while maintaining quality within defined limits.\n",
    "- **Duplicate Detection**: Uses hashing to ensure no duplicate images are processed.\n",
    "- **EXIF Data Utilization**: Extracts information such as the capture date and image orientation from EXIF data.\n",
    "- **Error Handling**: Identifies and moves corrupted or faulty images to a specific folder.\n",
    "- **Optimize Folder Structure**: Removes empty and unnecessary subfolders to create a flat and organized structure.\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. **Initialization**: Import necessary modules and define parameters like size limits and allowed file extensions.\n",
    "2. **Directory Preparation**: Create required folders for corrupted images and images without date information.\n",
    "3. **Image Processing**:\n",
    "   - **Validation**: Check if the file is a valid image and exceeds the minimum size.\n",
    "   - **Duplicate Checking**: Calculate an MD5 hash to identify already processed images.\n",
    "   - **Extract Year**:\n",
    "     - **From EXIF Data**: Attempt to extract the capture year from EXIF data.\n",
    "     - **From Filename**: If EXIF data is unavailable, extract the year from the filename using regex patterns.\n",
    "     - **Default Assignment**: Assign the image to the \"NoDate\" folder if no year can be determined.\n",
    "   - **Image Compression**: Compress images larger than a set limit to reach the target size.\n",
    "   - **Correct Orientation**: Adjust the image orientation based on EXIF data.\n",
    "   - **Storage**: Copy the processed image into the appropriate year directory in the destination folder.\n",
    "4. **Post-Processing**:\n",
    "   - **Flatten Folder Structure**: Merge folders with only one subfolder to simplify the structure.\n",
    "   - **Remove Empty Folders**: Delete empty folders that are no longer needed.\n",
    "5. **Logging**: Record all errors and exceptions in a log file for easy tracking.\n",
    "\n",
    "## Parameters and Settings\n",
    "\n",
    "- **Size Limits**:\n",
    "  - `small_size_limit`: 3 MB – Images above this size will be compressed.\n",
    "  - `medium_size_limit`: 10 MB – Additional compression level for very large images.\n",
    "  - `target_size_limit`: 6 MB – Target size for compressed images.\n",
    "  - `min_image_size`: 0.05 MB – Minimum size for an image to be processed.\n",
    "- **Directories**:\n",
    "  - `corrupted_folder`: Folder for corrupted images.\n",
    "  - `nodate_folder`: Folder for images without a determined date.\n",
    "- **File Extensions**: Allowed extensions are `.jpg`, `.jpeg`, `.png`, `.tiff`, `.bmp`, `.gif`.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- **Python Modules**:\n",
    "  - Standard libraries: `os`, `shutil`, `hashlib`, `re`, `time`, `logging`\n",
    "  - External libraries: `PIL` (Pillow), `tqdm`\n",
    "- **EXIF Support**: Images should contain EXIF metadata for certain features to work.\n",
    "\n",
    "## Usage\n",
    "\n",
    "1. **Set Directories**:\n",
    "   - Define the `source_directory` as the path containing the images to be processed.\n",
    "   - Define the `destination_directory` where the organized images will be stored.\n",
    "2. **Run the Script**:\n",
    "   - Ensure all prerequisites are installed.\n",
    "   - Execute the script in a Python environment.\n",
    "3. **Monitor Output**:\n",
    "   - Processed images will be organized in the destination directory.\n",
    "   - Logs will be recorded in `error_log.log`.\n",
    "   - A summary of processing statistics will be displayed upon completion.\n",
    "\n",
    "## Notes\n",
    "\n",
    "- **Error Handling**: The script logs errors to `error_log.log`. Check this file if issues arise.\n",
    "- **Performance**: The script uses `tqdm` for progress indication, which may slightly affect performance.\n",
    "- **Backup**: Always backup your images before processing to prevent data loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06f4a391-4b1d-45de-89f1-1221e98c417f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  17%|█▋        | 34511/202318 [1:44:37<1:23:46, 33.39it/s]  C:\\Users\\ahmed\\OneDrive\\anaconda\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:870: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "Processing images:  18%|█▊        | 36934/202318 [1:50:54<29:19:07,  1.57it/s]C:\\Users\\ahmed\\OneDrive\\anaconda\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:870: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "Processing images: 100%|██████████| 202318/202318 [13:44:58<00:00,  4.09it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 172982 images.\n",
      "Total size before: 444309.82852745056 MB\n",
      "Total size after: 171154.7778558731 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import hashlib\n",
    "import re\n",
    "import time\n",
    "from PIL import Image, ExifTags\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(filename='error_log.log', level=logging.ERROR)\n",
    "\n",
    "# Define compression thresholds and size limits\n",
    "small_size_limit = 3 * 1024 * 1024  # 3 MB\n",
    "medium_size_limit = 10 * 1024 * 1024  # 10 MB\n",
    "target_size_limit = 6 * 1024 * 1024  # 6 MB\n",
    "min_image_size = 0.05 * 1024 * 1024  # 0.05 MB (50 KB) - Minimum valid image size\n",
    "allowed_extensions = ['.jpg', '.jpeg', '.png', '.tiff', '.bmp', '.gif']\n",
    "\n",
    "# Directory for corrupted files and \"NoDate\" folder\n",
    "corrupted_folder = \"CorruptedImages\"\n",
    "nodate_folder = \"NoDate\"\n",
    "\n",
    "# Ensure directories for corrupted files and NoDate exist\n",
    "os.makedirs(corrupted_folder, exist_ok=True)\n",
    "os.makedirs(nodate_folder, exist_ok=True)\n",
    "\n",
    "# Function to extract the year from EXIF data\n",
    "def get_image_year(file_path):\n",
    "    try:\n",
    "        img = Image.open(file_path)\n",
    "        exif_data = img._getexif()\n",
    "        if exif_data:\n",
    "            for tag, value in exif_data.items():\n",
    "                decoded_tag = ExifTags.TAGS.get(tag, tag)\n",
    "                if decoded_tag == 'DateTimeOriginal':\n",
    "                    year = value.split(\":\")[0]\n",
    "                    if validate_year(year):\n",
    "                        return year\n",
    "    except Exception as e:\n",
    "        logging.error(f\"EXIF extraction failed for {file_path}: {e}\")\n",
    "    return None\n",
    "\n",
    "# Function to extract the year from a filename by matching common patterns\n",
    "def extract_year_from_filename(filename):\n",
    "    date_patterns = [\n",
    "        r\"IMG[_-](\\d{4})(\\d{2})(\\d{2})\",   # Matches IMG_YYYYMMDD or IMG-YYYYMMDD\n",
    "        r\"(\\d{4})[-_](\\d{2})[-_](\\d{2})\",  # Matches YYYY-MM-DD or YYYY_MM_DD\n",
    "        r\"(\\d{8})\",                        # Matches YYYYMMDD\n",
    "        r\"(\\d{4})\"                         # Matches any standalone year (fallback)\n",
    "    ]\n",
    "    \n",
    "    for pattern in date_patterns:\n",
    "        match = re.search(pattern, filename)\n",
    "        if match:\n",
    "            year = match.group(1)\n",
    "            if validate_year(year):\n",
    "                return year\n",
    "    return None  # Return None if no valid date is found\n",
    "\n",
    "# Function to validate the extracted year (only accept years between 2000 and 2030)\n",
    "def validate_year(year):\n",
    "    try:\n",
    "        year = int(year)\n",
    "        if 2000 <= year <= 2030:\n",
    "            return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    return False\n",
    "\n",
    "# Check if the file is a valid image and is larger than 0.05MB using PIL\n",
    "def is_image(file_path):\n",
    "    try:\n",
    "        if os.path.getsize(file_path) < min_image_size:\n",
    "            return False  # Ignore images smaller than 0.05MB\n",
    "        img = Image.open(file_path)\n",
    "        img.verify()  # This will raise an exception if the file is not an image\n",
    "        return True\n",
    "    except (IOError, SyntaxError):\n",
    "        return False\n",
    "\n",
    "# Calculate the hash of the image to avoid duplicates\n",
    "def calculate_hash(file_path):\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()\n",
    "\n",
    "# Fix image orientation based on EXIF data more reliably using Pillow's `ImageOps` module\n",
    "def fix_orientation(img):\n",
    "    try:\n",
    "        exif = img._getexif()\n",
    "        if exif is not None:\n",
    "            orientation_key = 274  # Exif key for orientation\n",
    "            if orientation_key in exif:\n",
    "                orientation = exif[orientation_key]\n",
    "\n",
    "                # Rotate according to EXIF orientation\n",
    "                if orientation == 3:\n",
    "                    img = img.rotate(180, expand=True)\n",
    "                elif orientation == 6:\n",
    "                    img = img.rotate(270, expand=True)\n",
    "                elif orientation == 8:\n",
    "                    img = img.rotate(90, expand=True)\n",
    "    except (AttributeError, KeyError, IndexError):\n",
    "        pass  # If the image has no EXIF orientation data, do nothing\n",
    "    return img\n",
    "\n",
    "# Compress the image based on its size, preserve EXIF, and store it in the destination folder\n",
    "def compress_image(image_path, dest_dir, target_size_mb=6):\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    # Fix the image orientation based on EXIF data\n",
    "    img = fix_orientation(img)\n",
    "\n",
    "    # Extract EXIF data\n",
    "    exif_data = img.info['exif'] if 'exif' in img.info else None\n",
    "\n",
    "    quality = 95  # Start with high quality\n",
    "    img_format = img.format if img.format != 'JPEG' else 'JPEG'\n",
    "\n",
    "    # Create the compressed image path inside the destination directory\n",
    "    output_path = os.path.join(dest_dir, os.path.basename(image_path))\n",
    "\n",
    "    # Save the image with EXIF data preserved\n",
    "    img.save(output_path, format=img_format, quality=quality, exif=exif_data)\n",
    "\n",
    "    while os.path.getsize(output_path) > target_size_mb * 1024 * 1024:\n",
    "        quality -= 10\n",
    "        if quality < 10:\n",
    "            break  # Stop if quality becomes too low\n",
    "        img.save(output_path, format=img_format, quality=quality, exif=exif_data)\n",
    "\n",
    "    return output_path  # Return the path of the compressed image\n",
    "\n",
    "# Function to flatten folder structure if it contains only one subfolder\n",
    "def flatten_single_subfolder_folders(folder_path):\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        # If the folder has only one directory and no files, flatten it\n",
    "        if len(dirs) == 1 and not files:\n",
    "            single_dir = dirs[0]\n",
    "            src = os.path.join(root, single_dir)\n",
    "            parent = os.path.dirname(root)\n",
    "            new_path = os.path.join(parent, os.path.basename(single_dir))\n",
    "            if not os.path.exists(new_path):\n",
    "                shutil.move(src, parent)  # Move the subfolder up\n",
    "                os.rmdir(root)  # Remove the empty intermediate folder\n",
    "\n",
    "# Function to remove empty folders after processing\n",
    "def remove_empty_folders(destination_dir):\n",
    "    for root, dirs, files in os.walk(destination_dir, topdown=False):\n",
    "        if not files and not dirs:  # If the folder is empty\n",
    "            os.rmdir(root)\n",
    "\n",
    "# Function to organize images into year-based folders (copy instead of move)\n",
    "def organize_images(source_dir, destination_dir):\n",
    "    os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "    processed_images = set()\n",
    "    if os.path.exists('processed_images.txt'):\n",
    "        with open('processed_images.txt', 'r') as f:\n",
    "            processed_images.update(f.read().splitlines())\n",
    "\n",
    "    # Count all images in all folders for a single progress bar\n",
    "    total_images = sum([len(files) for r, d, files in os.walk(source_dir) if files])\n",
    "\n",
    "    image_count = 0\n",
    "    total_size_before = 0\n",
    "    total_size_after = 0\n",
    "\n",
    "    with open('processed_images.txt', 'a') as processed_file, tqdm(total=total_images, desc=\"Processing images\") as pbar:\n",
    "        for root, dirs, files in os.walk(source_dir):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                if not is_image(file_path) or file_path in processed_images:\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "\n",
    "                image_count += 1\n",
    "                total_size_before += os.path.getsize(file_path)\n",
    "\n",
    "                # Calculate the hash to avoid duplicate processing\n",
    "                file_hash = calculate_hash(file_path)\n",
    "                if file_hash in processed_images:\n",
    "                    pbar.update(1)\n",
    "                    continue  # Skip duplicate images\n",
    "\n",
    "                # Extract the year from EXIF data or filename, validate the year\n",
    "                year = get_image_year(file_path) or extract_year_from_filename(file) or \"NoDate\"\n",
    "\n",
    "                # Define destination directory with year and folder structure\n",
    "                relative_path = os.path.relpath(root, source_dir)\n",
    "                dest_dir = os.path.join(destination_dir, year, relative_path)\n",
    "                os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "                # Determine compression strategy based on size\n",
    "                file_size = os.path.getsize(file_path)\n",
    "                if file_size > small_size_limit:\n",
    "                    try:\n",
    "                        # Compress and save directly in the destination folder (no extra copy step)\n",
    "                        compress_image(file_path, dest_dir)\n",
    "                        total_size_after += os.path.getsize(os.path.join(dest_dir, file))\n",
    "                    except PermissionError as e:\n",
    "                        logging.error(f\"Permission denied for {file_path}: {e}\")\n",
    "                        pbar.update(1)\n",
    "                        continue\n",
    "                    except Exception as e:\n",
    "                        logging.error(f\"Compression failed for {file_path}: {e}\")\n",
    "                        # Retry copying the file to the corrupted folder\n",
    "                        retries = 3\n",
    "                        for attempt in range(retries):\n",
    "                            try:\n",
    "                                shutil.copy2(file_path, os.path.join(corrupted_folder, file))\n",
    "                                break\n",
    "                            except PermissionError as e:\n",
    "                                logging.error(f\"Retry {attempt+1}/{retries} failed for {file_path}: {e}\")\n",
    "                                time.sleep(1)  # Sleep for a second and retry\n",
    "                                if attempt == retries - 1:\n",
    "                                    logging.error(f\"Copying to CorruptedImages failed for {file_path}: {e}\")\n",
    "                                    continue\n",
    "                else:\n",
    "                    try:\n",
    "                        shutil.copy2(file_path, os.path.join(dest_dir, file))  # Copy without compression\n",
    "                    except PermissionError as e:\n",
    "                        logging.error(f\"Permission denied for {file_path}: {e}\")\n",
    "                        pbar.update(1)\n",
    "                        continue\n",
    "\n",
    "                processed_file.write(f\"{file_hash}\\n\")\n",
    "                processed_images.add(file_hash)\n",
    "                pbar.update(1)\n",
    "\n",
    "        # Flatten folder structure after all files are processed\n",
    "        flatten_single_subfolder_folders(destination_dir)\n",
    "\n",
    "    # Remove empty folders\n",
    "    remove_empty_folders(destination_dir)\n",
    "\n",
    "    # Final summary\n",
    "    print(f\"Processed {image_count} images.\")\n",
    "    print(f\"Total size before: {total_size_before / (1024 * 1024)} MB\")\n",
    "    print(f\"Total size after: {total_size_after / (1024 * 1024)} MB\")\n",
    "    \n",
    "# Example usage\n",
    "source_directory = r\"E:\\Pictures\\\"\n",
    "destination_directory = r\"C:\\Users\\XYZ\\OneDrive\\Media\"\n",
    "\n",
    "organize_images(source_directory, destination_directory)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
